\documentclass{elsarticle}
\usepackage{amsfonts,xcolor,verbatim}
\usepackage{amssymb}
\usepackage{amsmath}
\newcommand{\X}{\mathrm{X}}
\newcommand{\Xh}{\hat{\mathrm{X}}}
\newcommand{\transpose}{^\mathrm{T}}
\usepackage{geometry}
\usepackage{url}
\usepackage[boxed]{algorithm2e}
\usepackage{algorithmicx,algpseudocode}
\newcommand{\argmax}{\operatornamewithlimits{argmax}}
\newcommand{\argmin}{\operatornamewithlimits{argmin}}

\begin{document}
<<setup, include=FALSE, cache=FALSE,eval=FALSE>>=
options(xtable.comment = FALSE)
options(replace.assign=TRUE,width=90)
options( digits = 4 )
# knit_hooks$set(rgl = hook_rgl)
# head(hook_rgl)  # the hook function is defined as this
@


\title{Sparse Canonical Correlation Analysis Relates Network-level Atrophy 
to Multivariate Cognitive Measures in Neurodegenerative Diseases}
\author{Brian B. Avants}
\begin{abstract}
This study establishes that sparse canonical correlation analysis (SCCAN) identifies generalizable, structural MRI-derived cortical networks that relate to five distinct categories of cognition.  We obtain multivariate psychometrics from the domain-specific sub-scales of the Philadelphia Brief Assessment of Cognition (PBAC).  By using a training and separate testing stage, we find that PBAC-defined cognitive domains of language, visuospatial functioning, episodic memory, executive control, and social functioning correlate with unique and distributed areas of reduced GM density.  In contrast, a parallel univariate framework fails to identify, from the training data, regions that are also significant in the left-out test dataset. The cohort includes 164 patients with Alzheimer's disease, behavioral-variant frontotemporal dementia, semantic variant primary progressive aphasia, non-fluent/agrammatic primary progressive aphasia, or corticobasal syndrome.  The analysis is implemented with open-source software for which we provide examples in the text.  In conclusion, we show that multivariate techniques identify biologically-plausible brain regions supporting specific cognitive domains.  The findings are identified in training data and confirmed in test data. 
\end{abstract}
\begin{keyword}
Alzheimer disease; frontotemporal lobar degeneration; Philadelphia Brief Assessment of Cognition, PBAC, MRI, sparse canonical correlation analysis.
\end{keyword}
\maketitle

% \cite{Norman2006}

\section{Introduction} 
Multivariate methods are frequently preferred over univariate methods in genomics \cite{Parkhomenko2009,LeFloch2012,Hibar2011}, pattern recognition \cite{Bishop1995,roberts_parametric_1997,Tipping2001} and neuroimaging \cite{McIntosh1996,DeMartino2008,Fan2008,Tosun2012} due to the high dimensionality and latent structure within these types of datasets.  Various forms of multivariate pattern analysis (MVPA) \cite{Norman2006,Hanke2009} are becoming the preferred methodology for functional magnetic resonance imaging (fMRI) studies \cite{McIntosh1996,Norman2006,OToole2007,Yamashita2008,SomethingFromHabeck}.  Recently,  multivariate analysis of structural MRI has gained more attention \cite{Ryali2010,Grosenick2013,ben,mert}.  The large majority of these techniques relate a multivariate pattern to a univariate outcome.  

Modern datasets allow the opportunity to relate two independent multivariate patterns.  Neuroimaging and psychometric batteries describe cognition and the brain itself, respectively, with a matrix of quantitative measurements.  These types of datasets may be analyzed with methods such as canonical correlation analysis (CCA) which is closely related to multivariate regression and partial least squares \cite{Sun2009}.  Partial least squares (PLS), without sparseness, has been used for several years in multivariate brain mapping studies \cite{McIntosh1996,Leibovitch1999,Lin2003,Addis2004a,Chen2009a}.  Ridge and related penalties allow these methods to be applied even when the number of subjects is far fewer than the number of measurements \cite{Nestor2002}.  However, a caveat of these approaches is that the resulting solution vectors have global extent i.e. cover the entire brain with basis vectors that are non-zero and may have both positive and negative values.  Traditional approaches are more clearly directional: a long neurological history is founded on relating behavioral deficits (losses) associated with destruction of brain tissue by stroke or related disorders.  Perhaps the most famous example is H.M.  This epilepsy patient lacked the ability to form new memories after anterior temporal lobe resection.  That is, loss of a specific part of the brain resulted in a specific deficit.  

Tools such as independent component analysis and principal components analysis (PCA) \cite{mansfield_analytic_1977,comon_independent_1994,yeung_principal_2001,Borroni2012} increase power by efficiently describing data.  However, PCA solutions provide signed basis vectors with global support and therefore lose the specificity of classical region of interest approaches or lesion studies.  Sparse multivariate methods have advantages of interpretability and, potentially, improved generalizability \cite{lee_learning_1999,Suykens2002,Tipping2001,Yamashita2008,Ryali2010}.  In this paper, we use the cognitive variance induced by a spectrum of neurodegenerative conditions to examine how new, sparse multivariate analysis techniques more powerfully reveal relationships between brain and behavior.  At the same time, sparse methods achieve a degree of specificity that cannot naturally be obtained by dimensionality reduction tools such as PCA \cite{lee_learning_1999}.  Here, we apply sparse multivariate methods to find cortical networks that vary with cognition in a mixed group composed of controls and phenotypes related to Alzheimer's disease (AD) and Frontotemporal lobar degeneration (FTLD) pathology.

Like AD, FTLD is a progressive neurodegenerative condition that is accompanied by changes in behavior.  Unlike AD, which typically presents atrophy in the precuneus and temporal lobes, FTLD's pathology occurs more frequently in frontal and temporal lobes\cite{Rabinovici2007,Whitwell2007d,}.  Several FTLD phenotypes have been identified, including patients with a disorder of social comportment and executive functioning (bvFTD); a non-fluent/agrammatic variant of primary progressive aphasia (naPPA), also known as progressive non-fluent aphasia; a semantic variant of primary progressive aphasia (svPPA), also known as semantic dementia; and corticobasal syndrome (CBS).  A common test used to screen for cognitive deficits in dementia is the Mini-Mental State Examination \cite{Hill1995}. However, it is now well understood that the MMSE does not assess the behavioral and cognitive deficits associated with FTLD \cite{Hutchinson2007}.  Other tests have been developed to screen and compare patients with dementia syndromes, including the Frontal Assessment Battery \cite{Dubois2000} (FAB); the Addenbrooke Cognitive Examination \cite{Galton2005} (ACE); and the Montreal Cognitive Assessment (MoCA) \cite{Nasreddine2005}.

The Philadelphia Brief Assessment of Cognition \cite{Libon2007,libon_philadelphia_2011} (PBAC) was developed to provide an economical means to screen and assess important domains of cognitive and behavioral impairment associated with AD and FTLD spectrum phenotypes.  The PBAC requires about 12 minutes for administration and scoring.  An important component of the PBAC is the construction of sub-scales designed to assess specific cognitive and behavioral/ comportment deficits that typify AD and FTLD syndromes, including executive/ working memory, language, visuospatial/ constructional skills, verbal/ visual episodic memory, and behavior/ social comportment.  Dementia severity is assessed by summing all PBAC sub-scales.  Recent research with the PBAC has demonstrated that AD and FTLD patients present with specific areas of impairment on sub-scales that correspond to phenotypic syndromes \cite{libon_philadelphia_2011} \textcolor{black}{i.e. clinical diagnosis.}

The current study extends previous research with the PBAC \cite{libon_philadelphia_2011} by examining the gray matter neuroimaging correlates of PBAC's cognitive and social measurements in a large number of AD and FTLD patients.  \textcolor{black}{From a neurological perspective, the purpose, here, is to use the variance within these patients to assess brain and behavior relationships across multiple behavioral loci, as opposed to diagnosis.  From a technical perspective, the goal is to contrast univariate and multivariate techniques.}  To test the hypothesis that PBAC indirectly measures the integrity of different cortical networks (versus individual voxels), we employ a new data-driven machine learning technique, sparse canonical correlation analysis for neuroimaging (SCCAN), to associate high-dimensional imaging measurements with the full information provided by a multivariate psychometric battery such as PBAC.  Specifically, this approach allows an optimal weighting of psychometric sub-scales (as opposed to averaging their values) such that the relationship with neuroimaging is maximized.  At the same time, SCCAN optimizes and selects regions of gray matter (GM) to maximize correlation with psychometrics.  This results in a set of gray matter regions that may be interpreted as the network most-associated with the given psychometric domain.  SCCAN previously identified covariation between GM and diffusion tensor imaging white matter (WM) changes that optimally discriminate between CSF- and autopsy-defined patients with AD and FTLD \cite{Avants2010b}.  The purpose of the current research is to test the hypothesis that SCCAN may employ individual PBAC sub-scales to extract GM networks that are reproducibly associated with variation in cognition.  This would provide additional criterion validity for both the PBAC and multivariate techniques such as SCCAN, in contrast to univariate techniques, and establish a novel strategy for performing multivariate analyses of brain and behavior. 

\begin{figure*}[th] \centering
\includegraphics[width=0.9\textwidth]{./figs/sccan_study.pdf}
\caption{Diagram of the study.  The data splitting in step 1 happens only once.  We perform stage 2 and 3 for each of the five PBAC sub-scales.}
\label{fig:study}
\end{figure*}

\section{Methods} An overview of our study is in Figure~\ref{fig:study}.  We first discuss the core dataset and measurements.  We then discuss the PBAC and SCCAN methods.  We proceed with an evaluation framework, including a comparison against a univariate approach.
\subsection{Patients}  Individuals participating in the current research were drawn from a corpus of 270 patients, previously described \cite{libon_philadelphia_2011}.  Dementia patients were evaluated by experienced behavioral neurologists (AC, HBC, RGG, MG) and classified clinically on the basis of previously published criteria \cite{McKhann01,Rascovsky2011,Gorno-Tempini20111006}.  A research diagnosis was made on the basis of an independent review of a semi-structured history obtained from patients and their families and a detailed neurologic examination.  At least two trained reviewers from a consensus committee (inter-rater reliability, r= 0.91, p< 0.001) confirmed patients' clinical diagnosis and presence of a specific dementia syndrome involving AD or FTLD. Discrepancies were resolved based on group discussion and follow-up assessment.  The PBAC was not used for the initial diagnosis of research participants.  

The clinical diagnosis of dementia was consistent with serum studies, clinical studies of cerebrospinal fluid (when available), clinical imaging studies such as MRI or CT, and functional neuroimaging studies such as SPECT or PET (these studies were not available to the consensus committee).  Exclusion criteria included the presence of other neurologic conditions such as stroke or hydrocephalus, primary psychiatric disorders (e.g., major depression, psychosis), or a systemic illness that can interfere with cognitive functioning.  Some patients were taking a cholinesterase inhibitor (e.g. donepezil, galantamine), memantine, or a non-sedating anti-depressant (e.g., serotonin-specific re-uptake inhibitors such as sertraline), or an atypical neuroleptic agent (e.g., quetiapine) consistent with clinical care; however, no patient demonstrated evidence of sedation.  The current research examined patients with AD (n= 17), behavioral variant-FTD (bvFTD; n= 41), semantic variant-primary progressive aphasia (svPPA; n= 14), non-fluent/ agrammatic-primary progressive aphasia (nfaPPA; n= 15) and corticobasal syndrome (CBS; n= 24).  The imaging analysis also included elderly controls (n= 56) who were living independently in the community and not taking psychoactive medications.  Normal control participants presented with no cognitive complaints or impaired instrumental activities of daily living.  Table 1 summarizes participant demographic features.  This research was approved by the University of Pennsylvania Institutional Review Board and informed consent was obtained consistent with the Declaration of Helsinki.

\input{src/demog.txt}

\subsection{The Philadelphia Brief Assessment of Cognition (PBAC)} Full details regarding the rationale and construction of the PBAC can be found elsewhere \cite{libon_philadelphia_2011}.  The PBAC consists of 15 variables including 11 tests and 2 rating scales.  These variables are grouped into five sub-scales measuring: working memory/ executive control, language, visuospatial/ constructional ability, verbal/ visual episodic memory, and behavior/ social comportment.  The total PBAC score ranges between 0-93. 
The executive scale includes measurements of fluency, digits backward and digits forward.  The language scale measures naming, speech, reading, writing and semantic ability.  The memory scale quantifies delayed free recall, recognition and Rey recall.  The visuospatial scale measures judgement of line orientation (JOLO) and the Rey copy test.  The behavioral scale includes subjective measurements of apathy, disinhibition, social comportment, agitation, empathy and ritual.   The correlations between these different sub-scales are shown in Figure~\ref{fig:pbaccor}.  

\begin{figure*}[th] \centering
\includegraphics[width=0.9\textwidth]{figs/pbac_correlations.pdf}
\caption{We visualize, with a heatmap, the correlations between the different PBAC individual scales which are clustered together to form the sub-scales studied here.  The total PBAC is an average of the 5 sub-scale scores.  The sub-scales provide a reasonable separation of measurements.}
\label{fig:pbaccor}
\end{figure*}

\subsection{Image acquisition}  All images were acquired with a Siemens Trio 3.0 tesla MRI scanner.  Following a rapid sagittal T1-weighted scan to determine patient position, a T1-weighted structural image was acquired with TR= 1620ms, TE= 3ms, slice thickness= 1mm, in-plane resolution= 0.9766mm $\times$  0.9766mm, FOV= 256 $\times$ 192. 

\subsection{Image processing} 

The imaging analysis is based on the publicly available and open-source Advanced Normalization Tools (ANTs, \url{http://www.picsl.upenn.edu/ANTs/}) and the associated pipelining framework PipeDream (\url{http://neuropipedream.sourceforge.net}).  PipeDream automates and quality-assures ANTs processing via a single parameter file and data organization hierarchy.  Each patient's T1 imaging data are inhomogeneity corrected via the N4 bias correction algorithm \cite{Tustison2010}.  PipeDream then performs diffeomorphic normalization via the top-performing symmetric normalization methodology available in ANTs \cite{Avants2008,Avants2011a,wbir2012,Tustison2012} to map each subject to a population-specific template built from the same scanner and imaging parameters.  The template contains prior labeling and probability maps that are used to guide both brain extraction and neuroanatomical segmentation.  Segmentation is performed with a Markov Random Field approach \cite{Avants2011} implemented in the ANTs toolkit which has been validated on publicly-available datasets.  GM probability maps are then smoothed by a 2mm Gaussian kernel, mapped to the template space, and down-sampled to 2mm resolution.  These normalized GM probability maps are used for subsequent multivariate correlation with PBAC.

\subsection{Dimensionality reduction/Statistical Analysis} 

There are two primary reasons that univariate approaches lack power.  First, power is compromised because the same test is repeated at each measurement site leading to an often severe multiple comparisons problem.  Second, univariate methods do not exploit the latent signal in the data that is spread across measurement sites.  In this study, rather than perform voxel-wise testing, we employ a dimensionality reduction method implemented in SCCAN.  Briefly, this is an imaging-specific extension of sparse canonical correlation analysis \cite{Avants2010,Cao2009,parkhomenko,witten_extensions_2009-1,witten} that is itself a sparse extension to Hotelling's seminal canonical correlation analysis (CCA) \cite{Hotelling1936,hotellingcca}.  CCA, in turn, is a multi-modality extension to  principal component analysis. 

Classical CCA may be used to compute a multivariate association between two different views of a dataset.  One of Hotelling's original examples associated measurements of height and weight to measurements of cognition.  More recently, sparse versions of CCA have been developed to increase the interpretability of the output where we take motivation for sparse methods from our introductory material.  Sparse CCA methods, like classical CCA, compute eigenvectors (in actuality, {\em pseudo}-eigenvectors) that maximize the Pearson correlation between the input modalities.  In this work, we use sparse CCA in a similar way to Hotelling's classic study, i.e. to associate two different types of measurements, one anatomical and one psychometric, in a population.

We employed the SCCAN implementation of sparse CCA to directly associate the five PBAC sub-scales described above with GM measures taken from T1-weighted MR images.   In general, SCCAN elucidates the relationship between two sets of measurements taken across a population and is thus well-suited to multivariate neuroimaging data.  The input to SCCAN is two matrices $X$ and $Y$.  The size of $X$ is $n \times p$ where $n$ is the number of subjects and $p$ is the number of voxels from the cortical gray matter.  The matrix thus collects all cortical imaging data for each subject.  The size of $Y$ is $n \times q$ where there are $q$ psychometric measurements in the given PBAC sub-scale i.e. $q=3$ for executive, $5$ for language, $3$ for memory, $2$ for visuospatial and $6$ for behavioral scales \footnote{One column of the behavioral scales (self insight) was excluded due to lack of variance}.  SCCAN maximizes the Pearson correlation, in a rotated space, between non-negatively weighted columns of these matrices.   More formally, SCCAN,  like classic CCA, introduces new unknown solution vectors, $x$ ( $p \times 1$ ) and $y$ ( $q \times 1$ ) that act as weight functions on columns of $X$, $Y$.   The SCCAN optimization criterion is: 
%
%                                         arg max   Corr( X x, Y y)  -  w || x ||  - v || y ||, 
%			     subject to:    x  >= 0,
%
\begin{eqnarray} 
\label{eq:cca}
 x^\star,~y^\star  =
\underset{x,y}{\operatorname{arg\,max}} \quad~
 ~~\frac{x~X^T ~Y~y}{\| X x \|~\| Y y \|}~\\ \notag \text{subject to} \\ \notag \sum_j
\|x^j\|_1 \leq s,~~ x^j \ge 0,
\end{eqnarray} where $x^\star$, $y^\star$ are the optimal solution vectors, $x^j$ denotes the $j^\text{th}$ entry of $x$, $s$ determines the sparseness level and $\|\cdot\|_1$ denotes the $\ell_1$ norm. The $\ell_1$ norm forces the solution $x$ to be sparse i.e. have zero value over the majority of the brain.  In this application, we do not enforce sparseness on the $y$ vector as it is relatively small, i.e. $q << n$.  SCCAN's objective function can be optimized even when the matrices are “fat” i.e. $p >> n$, often the case in neuroimaging studies.  Due to the non-linear (even np-hard) nature of subset selection (sparse optimization) from a large matrix, optimizing for a single canonical variate pair, $x, y$, involves a nonlinear gradient descent on the objective function above. 
The analytical gradient of the objective function (ignoring the $\ell_1$
and positivity constraints) w.r.t. $x$ is:
\begin{gather}
\label{eq:ccagrad}
X^T Y y - \frac{1}{2} X^T X x \| X x \| \| Y y \|. 
\end{gather}
Following this gradient will cause the candidate solution $x$ to leave the
permissible solution space and, as such, we follow the gradient update
step with a projection step as in
\cite{Polak1997,schwartz_family_1997}.  The projection step involves a
standard soft-thresholding operation used in $\ell_1$ optimization
which is easily modified to include positivity constraints
\cite{donoho_-noising_1995,tibshirani_regression_1996,elad_why_2006,witten_extensions_2009-1}.
The gradient for $y$ is obtained at the same time as that for $x$ with a simple switching of
variables.  Following, we refer to $x^\star$ as $x$ and $y^\star$ as $y$.  

SCCAN therefore produces a sparse projection vector acting on GM voxels that, taken as a set, maximally correlate with the user-selected PBAC domain of interest.  Here we use the working memory/executive, language, visuospatial, memory, and social/behavioral PBAC sub-scales, thus requiring only five direct multivariate tests, i.e., one for each cognitive domain.  The sparse eigenvectors that emerge from SCCAN identify the brain regions supporting the specific PBAC domain that was passed to the algorithm as the second view.  In this study, we restrict the SCCAN eigenvectors to be positive.  Thus, each eigenvector can be reinterpreted as a weighted average of values over a restricted region of GM, like a region of interest \cite{roi_analysis,zhou_hierarchical_2011,Rasmussen2012,Chen2010}.  This may be achieved in a post-processing step that sets the sum of the solution vector, $x$ or $y$, to equal one.  The implementation details are available in the Advanced Normalization Toolkit's \verb sccan.cxx ~program which contains the SCCAN source code.  The significance of SCCAN results may be tested by permuting one of the two views over many different simulations.  One then compares the correlation value produced by the original ordering of the data to the correlations produced over the $N$ permutations. Large $N$ (typically $>1000$) is needed to provide a reasonable sampling of the empirical null distribution.  In this analysis, we use a training and testing paradigm \footnote{as recommended by reviewers} to avoid permutation testing and to allow us to perform parameter selection (for $s$) on the training dataset in a manner that is independent of the test dataset. 

\begin{figure*}[th] \centering
\includegraphics[width=0.18\textwidth]{./figs/sccan_param_behav.pdf}
\includegraphics[width=0.18\textwidth]{./figs/sccan_param_exec.pdf}
\includegraphics[width=0.18\textwidth]{./figs/sccan_param_lang.pdf}
\includegraphics[width=0.18\textwidth]{./figs/sccan_param_mem.pdf}
\includegraphics[width=0.18\textwidth]{./figs/sccan_param_vs.pdf}
\caption{A one parameter search over sparseness, in the training dataset, allows us to identify the optimal sparseness parameter for each cognitive domain.  The network variables $x^\star$ and $y^\star$ that arise from SCCAN computed at the optimal sparseness level will be evaluated in the test dataset for reproducibility.}
\label{fig:param}
\end{figure*}

\subsection{Parameter Selection}  
\subsubsection{Image Processing}
Our studies used reproducible research practices by employing open methods, standardized parameter sets and version control of both parameters and code via git.  We employed standard parameters in PipeDream and ANTs for template construction, normalization, segmentation and GM estimation.  These analysis protocols are described elsewhere \cite{}. 

\subsubsection{Statistical Parameters}
SCCAN was used to extract the single most dominant features associating GM and a PBAC sub-scale in a training dataset.  Our study design involves setting only a single parameter, $s$, which controls the sparseness of the imaging space solution vector, $x$.  We chose to restrict $x$ to also be non-negative such that the solutions can be interpreted with clear directionality i.e. as a weighted average.  To identify the parameter $s$, we run SCCAN with a range of $s^{\text{candidate}}$ values ($s=0.005,0.01,\cdots,0.2)$ and store the resulting SCCAN correlation for each trial.  We then fit a model, $ \text{SCCAN-Correlation} \approx   \beta_1 s^{\text{candidate}} + \beta_2 ( s^{\text{candidate}} )^2 +  \beta_3 ( s^{\text{candidate}} )^3 + \beta_4 ( s^{\text{candidate}} )^4$, to the function mapping $s \to $ SCCAN-Correlation.  We set the the final parameter $s$ to correspond to the value of our model that maximizes the dependent SCCAN-Correlation value.  If there are ties, we take the first from the left (maximally sparse) solution.   We then compute the final solutions $x^\star, y^\star$ that will be evaluated for reproducibility in our test dataset.  We did not employ sparseness on the 2nd view (the PBAC sub-scale scores).  In total, we need only perform $5$ tests total as opposed to 5$p$ tests required by a univariate setting.  Here, $p=90,084$ and $5p=450,420$.  Parameter selection results are in Figure~\ref{fig:param}.

\subsection{Comparison of Univariate to Multivariate Feature Selection}
This study employs a training and testing paradigm.  Therefore, SCCAN may be viewed as a tool that generates ``feature vectors" ($x, y$) that are optimized in a multivariate manner to associate GM and PBAC.  Using our existing terminology, these maximize $Corr( X x  , Y y )$ where $Corr$ denotes Pearson correlation and $X, Y$ correspond to the training dataset matrices.  
These feature vectors may be used as ``hypotheses" and applied to a new testing dataset, $X_\text{test}, Y_\text{test}$, to determine if the patterns extracted from training data are reliable in test data.  In this analysis, we use the correlation in test data as our outcome measurement which is computed as $\text{Outcome}_\text{Multivariate}=Corr( X_\text{test} x, Y_\text{test} y )$ where $x, y$ derive from training data. 


\begin{figure*}[th] \centering
\includegraphics[width=0.9\textwidth]{./figs/results.pdf}
\caption{The PBAC sub-scales and their corresponding putative support regions in the cortex, as identified by SCCAN and verified in testing data.}
\label{fig:results}
\end{figure*}

We can also compute a parallel univariate outcome, $\text{Outcome}_\text{univariate}$, via a similar methodology based on univariate feature selection.  We use Occam's razor to decide upon a univariate feature selector i.e. we do something simple-minded yet akin to several other studies \cite{Chen2010,dickerson_mri_2012}.  We compute the univariate p-values of a model associating the PBAC sub-scale summary measurement (an average of the $Z$ transformations of the individual measurements within the sub-scale) with each voxel in the cortex.  This univariate model may be written PBAC-sub-scale $\approx v_i$ where $v_i$ is a vector containing the subject GM values at a given voxel (so $i$ takes values $1 \cdots p$).  The p-value associated with $v_i$ is then denoted $p_i$.  Now, define $u$ as a $p$-length weight vector similar to the weight vector $x$.  However, the entry at $u_i$ is zero if $p_i$ is $>0.01$ (unadjusted) and 1 otherwise. This finally allows us to define the univariate outcome as $\text{Outcome}_\text{univariate}=Corr( X_\text{test} u , \text{PBAC-sub-scale}_\text{test} )$.   

This protocol allows us to compare a joint multivariate feature selector that identifies weights on PBAC sub-scale values ($y$) and the brain ($x$) with a univariate feature selector acting only on the brain ($u$).  While the univariate approach does not weight the PBAC-sub-scale, it does use a standard average of the sub-scales commonly used in PBAC assessment.  Thus, we compare a new, fully multivariate approach, to an existing standard approach.  One may argue that the threshold selected to binarize the $u$ vector is arbitrary.  However, this is a common/standard style of analysis employed in univariate methods, i.e. select a significance threshold and accept the results as the truth.  The univariate solutions do not survive multiple comparisons correction so we had no choice but to use uncorrected p-values as feature selectors.


\begin{figure*}[th] \centering
\includegraphics[width=0.4\textwidth]{./figs/sccanpredictbehav.pdf}
\includegraphics[width=0.4\textwidth]{./figs/sccanpredictexec.pdf}
\includegraphics[width=0.4\textwidth]{./figs/sccanpredictlang.pdf}
\includegraphics[width=0.4\textwidth]{./figs/sccanpredictmem.pdf}
\includegraphics[width=0.4\textwidth]{./figs/sccanpredictvs.pdf}
\caption{We visualize the correlation between $X_\text{test} x^\star$ and $Y_\text{test} y^\star$ for each of the five PBAC sub-scales.}
\label{fig:test}
\end{figure*}

\section{Results}

We residualized the input matrices with respect to age, educational level (in years) and MMSE before sending them to the univariate and multivariate outcome procedure outlined in Figure~\ref{fig:study}.  

\subsection{Univariate: PBAC Sub-Scales and GM Density} No univariate outcome measurement achieves significance when relating brain and behavior in the test data.  That is, the correlation between PBAC-sub-scale$_\text{test}$ with $X_\text{test} u$ is weak in each of the five PBAC sub-scales (p-values: exec 0.93,  language 0.078,  memory 0.85, visuospatial 0.66, behavioral 0.78).  However, the relationship between PBAC-sub-scale$_\text{train}$ with $X_\text{train} u$ is strong, as expected (all p-value $< 0.01$).  This indicates that, at least in this dataset, naive univariate feature selection overfits to the training data.  

\subsection{Multivariate: PBAC Sub-Scales and GM Density}  
Based on training data, we found, in testing data, significant associations between GM density and each of the five PBAC sub-scales consistent with putative neuroanatomical substrates at the Bonferroni-corrected $p < 0.05$ level.  The raw p-values are exec 0.0001,  language 0.001,  memory 0.0001, visuospatial 0.001, behavioral 0.0001.  As summarized in Figure~\ref{fig:results} and Table~\ref{tab:behav}, PBAC-defined behavior/ social comportment was related to bilateral ventral and medial frontal and insula atrophy that is more prominent on the right than the left.  The memory sub-scales (Table~\ref{tab:mem}) was related to bilateral precuneus, bilateral hippocampus, and bilateral posterior temporal atrophy more prominently on the left than the right.  Significant visuospatial/ constructional impairment (Table~\ref{tab:vs}) was related to bilateral posterior temporal-occipital and bilateral parietal-occipital atrophy.  The language sub-scale (Table~\ref{tab:lang}) was related to left temporal and left temporal-parietal atrophy extending into left anterior temporal and left inferior frontal regions.  Executive deficits were related to bilateral dorsal and lateral prefrontal atrophy---FIXME.  The executive network is described in Table~\ref{tab:exec}.  

\input{src/behav_network.txt}

\input{src/exec_network.txt}

\input{src/lang_network.txt}

\input{src/mem_network.txt}

\input{src/vs_network.txt}


\begin{comment}
\subsection{Clinical Diagnosis and GM Density} PBAC sub-scales have previously been shown to differentiate between AD and FTLD, and between FTLD phenotypes9,libon_philadelphia_2011.  Linear regression was used to relate GM density to the diagnosis of interest while controlling for co-variates including age, education, disease duration.  Here, diagnosis is a binary predictor where a single patient group was compared to all other subjects not in the group of interest.  Results confirm that the weighted average GM density associated with most PBAC sub-scale was significantly related to diagnosis.  Specifically, PBAC behavior/social-related GM regions were related to bvFTD (p< 0.001).  Likewise, PBAC language-related GM regions were related to svPPA (p< 0.008).  PBAC memory-related GM regions were related to AD (p< 0.017) and PBAC visuospatial/ constructional-related GM regions were related to CBS (p< 0.001).  PBAC working memory/ executive-related GM regions were not related to one specific clinical diagnosis.  
\end{comment}

\section{Discussion}
This study establishes, for the first time, that sparse canonical correlation analysis finds repeatable relationships between multivariate psychometric batteries and network level gray matter density measurements.  Our analysis restricts the signs of the gray matter density solution vector, $x^\star$, to be sparse and positive enabling directional relationships to be established (i.e. low gray matter, low cognitive score).  The SCCAN multivariate analysis framework shows improved generalizability and power over the univariate method against which it is compared.  

This study also represents the first comparison of PBAC sub-scales to structural neuroimaging. The PBAC was designed as a screening instrument to assess overall dementia severity and to differentiate between neurodegenerative syndromes within the AD and FTLD spectrum.  Previous research with the PBAC found a significant correlation between the total PBAC score and the MMSE \cite{Libon2007,libon_philadelphia_2011}, thus demonstrating that performance on the instrument reasonably captures overall dementia severity. The psychometric qualities of the PBAC include good internal consistency among the tests within each PBAC sub-scale and highly significant intra-class correlations between PBAC sub-scales and standard neuropsychological tests \cite{libon_philadelphia_2011}.  PBAC sub-scales also show good clinical utility in distinguishing between AD and FTLD, and between FTLD-related phenotypes using sub-scale cut scores, although diagnosis is not the focus here. 

The current research used novel imaging methods to provide further evidence for the criterion validity of the PBAC by associating PBAC sub-scale test performance with corresponding areas of GM atrophy.  We found relationships between PBAC-defined areas of GM atrophy and specific cognitive domains.  Patients with AD are known to present with striking memory impairment as well as atrophy involving the hippocampus, precuneus and related anatomic structures.  In the current research, the PBAC memory sub-scale was associated GM involving bilateral hippocampus and precuneus.  Hippocampal and precuneus involvement in clinically-defined patients with anterograde amnesia and AD is well known \cite{Nestor2002b,Pengas2010}.  Moreover, prior research with AD and amnesic mild cognitive impairment suggests that these areas are part of a neurocognitive network for memory that also includes superior temporal gyrus \cite{Delano-Wood2012,Gardini2011}.  

bvFTD presents with alterations in behavior and social comportment \cite{Rascovsky2011,Shany-Ur2011}, including apathy, disinhibition, and lack of empathy.  In the current study, the PBAC-behavior/social scale is related to striking bilateral medial and ventral frontal GM atrophy, perhaps with greater right-sided involvement and the clinical diagnosis of bvFTD.  Previous research has associated these behavioral abnormalities with bilateral ventral and medial frontal atrophy \cite{Massimo2009,Rosen2010}.    
CBS is associated with significant impairment in visuospatial and visuoconstructional tests, as well as some executive deficits \cite{Libon2007,Libon2009}.  The current research associates the PBAC-visuospatial/ constructional sub-scale with right posterior GM atrophy.  Prior neuroimaging research with CBS patients is controversial, with some researchers suggesting both parietal and frontal atrophy \cite{Grossman2004b} and others only frontal involvement \cite{Hassan2011}.  In the present study, atrophy in visual association cortex associated with the visuospatial/constructional sub-scale identified individuals with the clinical diagnosis of CBS.  The executive/ working memory sub-scale is not typically associated with a single diagnosis but instead is associated with several diagnostic subgroups, including CBS.  This may reflect disease in this subgroup in frontal brain regions sensitive to the executive/working memory sub-scale.

The PBAC language sub-scale is primarily related to left temporal GM density, primarily with prominent posterior and inferior temporal GM.  These data are consistent with prior research demonstrating left temporal atrophy in patients with svPPA who have language-related cognitive impairment \cite{Bonner2009,Williams20051042}.  The measures on the PBAC language sub-scale focus mostly on object comprehension, single word expression, reading and writing, with little emphasis on the characteristics important for identifying naPPA \cite{Gorno-Tempini20111006}.  It is not surprising in this context that patients with naPPA are not associated with the language sub-scale of the PBAC.  Patients with this syndrome are particularly impaired on measures assessing grammatical processing and speech errors \cite{Gorno-Tempini20111006,Gunawardena2010}, and these domains of cognitive functioning are not currently part of the PBAC-language sub-scale.  Prior research with the PBAC has shown that patients with naPPA score lower on the PBAC-working memory/ executive sub-scale \cite{libon_philadelphia_2011,Libon2007} confirming executive and working memory deficits in these patients and reflecting their disease centered primarily in the frontal lobe \cite{Gunawardena2010,Rogalski2011}.  Future modifications of the PBAC may include measures to improve detection of the naPPA subgroup.

Finally, the PBAC-working memory/ executive sub-scale is related to dorsal and lateral prefrontal GM atrophy.  Although the PBAC-working memory/executive sub-scale consists of verbally-mediated tests, the frontal atrophy associated with the PBAC-working memory/executive sub-scale is bilateral.  This emphasizes the observation that difficulty on resource-demanding measures such as these is associated with bilateral disease and somewhat independent of the modality of task presentation \cite{Libon2009}.  Because executive and working memory measures involve multiple brain regions often working together with dorsal and lateral prefrontal areas, it is not surprising that this sub-scale is not associated with a single subgroup.  Taken together, these data extend past research to show that PBAC sub-scales are associated with MRI-defined anatomical substrates and that the PBAC is a sensitive clinical screening tool in AD and FTLD syndromes.  

The identified relationships between impaired neurocognitive GM networks and clinically-defined diagnoses in dementia underscore the power of SCCAN over traditional univariate approaches to imaging analysis.  In prior research \cite{Kipps2007}, a large group of patients with bvFTD, svPPA and nfPPA were evaluated with ACE and a MRI visual rating scale that graded temporal and frontal lobe atrophy on a 5-point scale \cite{Mathuranath2000a}.  In that study, 100% of svPPA patients were judged to have abnormal scans, 71% nfPPA patients were judged to have abnormal scans only 47% of bvFTD patients had abnormal scans.  The cognitive measure was significantly correlated with atrophy in all regions that were measured.  By contrast, there was no general correlation demonstrating increasing behavioral abnormalities with any areas of the brain.  However, for a subset of bvFTD patients, greater behavioral disturbance was correlated with greater atrophy involving bifrontal regions.

Using SCCAN, by comparison, massive dimensionality reduction significantly enhances the empirical ability to detect these behavioral and neuroimaging relationships.  Prior work demonstrated the advantages of SCCAN in combining GM and diffusion tensor imaging data to distinguish between autopsy- and CSF-defined cases of AD and FTLD \cite{Avants2010b}.  The results of the current study reveal that SCCAN is capable of associating multi-dimensional psychometric and neuroimaging data to reveal the large-scale neural networks that are degraded when cognition is compromised in neurodegenerative conditions like AD and FTLD.

There are several caveats to this study.  A primary technical issue is whether the network structure (i.e. distributed sets of voxels) that SCCAN extracts is either a minimal or maximal reliable network supporting the selected cognitive domain.  Indeed, it is likely that subsets of the voxels added to or subtracted from the SCCAN solutions may not alter predictive accuracy to a strong degree.  This hypothesis is strengthened by the fact that our sparseness vs correlation curves (Figure~\ref{fig:param}) are relatively smooth. However, identifying an optimally predictive set of high-dimensional variables across arbitrary subsets of a population is a generally unsolved problem.  We elected to address this by defining our networks based on a tractable parameter search strategy that maximizes the SCCAN correlation in training data.  A secondary issue is that our comparison with the univariate strategy may not be ideal.  There are several alternative approaches for univariate feature selection that may be employed with better results, for instance optimizing the recently proposed cluster-level FDR \cite{ClusterLevelFDR}.  We leave this question to future work by ourselves or others and also note that this approach would remain univariate in the dependent variable.  SCCAN, on the other hand, uses a multivariate treatment of both datasets, cognition and neuroimaging.

The clinical aspects of this research also has limitations.  First, the PBAC was not designed nor should it be used to as a substitute for a comprehensive neuropsychological evaluation. This is reflected most clearly in the modest ability of the executive/working memory sub-scale to detect a specific group of patients with prefrontal disease.  Second, the sample size for several groups was relatively modest.  The results of the present study will require confirmation with larger groups of patients.  Third, virtually all work with the PBAC has been confined to differentiating AD from FTLD and to distinguishing between FTLD phenotypes.  The utility of the PBAC in other populations such as Parkinson's disease, amyotrophic lateral sclerosis, and Mild Cognitive Impairment requires further examination.  Finally, SCCAN associated some unexpected brain regions with a specific cognitive domain.  For example, the insula was associated with the memory sub-scale and an area of the ventral temporal lobe with executive functioning.  Additional work is needed to understand the basis for these associations.  With these limitations in mind, the current study suggests good criterion validity for the PBAC to differentiate between AD and FTLD-related phenotypes, and the power of a multivariate analytic approach such as SCCAN to demonstrate these effects.  


\section{Acknowledgements}
Dr. Grossman receives support from the National Institutes of Health (AG32953, AG17586, AG15116, NS44266, and NS53488) and the Wyncote Foundation, and is a consultant for Bristol Meyers Squibb and Allon Therapeutics.  Dr. Chatterjee receives support from National Institutes of Health (RO1 DC008779, RO1 HD050199] and the National Science Foundation (SBE0541957).  Dr. McMillan receives support from NIH HD0406.  Ms. Massimo receives support from National Institutes of Health (F31NR013306) and John A. Hartford Foundation's Building Academic Geriatric Nursing Capacity Award Program.  Dr. Libon receives support for Bayer Pharmaceuticals.  Drs. Rascovsky and Avants, and Ms. Boller report no disclosures.

\section{ANTsR Example Code for SCCAN}

We first load the relevant libraries for this analysis.

<<libs, include=TRUE, cache=FALSE,eval=FALSE>>=
suppressPackageStartupMessages( library(ANTsR) )
library(xtable)
library(abind)
library(grDevices)
library(visreg) 
library(vegan)
@

Several organizational steps are not included.  The key steps of univariate and multivariate feature selection, along with assessment on testing data, are shown below. 

<<cca1,include=FALSE, eval=FALSE,echo=FALSE>>=

####################
DIR<-paste(getwd(),'/data/',sep='')
tem<-antsImageRead( paste(DIR,'ch2bet.nii.gz',sep='') , 3 )
resMV<-list()
if ( ! exists("resUV") ) resUV<-list()
if ( length( resUV ) != 5 ) resUV<-list()
 if ( ! exists("sparMV") ) sparMV<-list()
if ( length( sparMV ) != 5 ) sparMV<-list()
##########################################################################
##########################################################################
demogin<-read.csv(paste(DIR,'PBAC_current.csv',sep=''),na.strings = ".")
demog<-demogin
for ( j in   1:dim(demog)[2] ) {
  demog[,j]<-as.numeric(as.character(demog[,j]))
}
lookatrows<-grep("adj",names(demog))
testnames=names(demog)
agenthelike<-c(13:15,176)
agenthelike<-c(13:15)
offset<-length(agenthelike)  # this will add the age / mmse to the matrix 
offset<-0                               # only pbac 
testlist<-1:5
for ( opt in testlist ){ # 
if ( opt == 1 ) {
  lookatrows<-c(agenthelike,46:48) ; nam<-'exec' # exec + demog
  if ( offset == 0 ) lookatrows<-c(46:48) ; nam<-'exec' # exec + demog
}
if ( opt == 2 ) {
  lookatrows<-c(agenthelike,50:54) ; nam<-'lang' # lang + demog
  if ( offset == 0 ) lookatrows<-c(50:54) ; nam<-'lang' # lang + demog
}
if ( opt == 3 ) {
  lookatrows<-c(agenthelike,59:61) ; nam<-'mem' # mem + demog
  if ( offset == 0 ) lookatrows<-c(59:61) ; nam<-'mem' # mem + demog
}
if ( opt == 4 ) {
  lookatrows<-c(agenthelike,56,57) ; nam<-'vs' # vs + demog
  if ( offset == 0 ) lookatrows<-c(56,57) ; nam<-'vs' # vs + demog
}
if ( opt == 5 ) {
  lookatrows<-c(agenthelike,36,37,39,40,41) ; nam<-'behav' # behav + demog
  lookatrows<-c(agenthelike,37:42) ; nam<-'behav' # behav + demog
  if ( offset == 0 ) lookatrows<-c(37:42) ; nam<-'behav' # behav + demog
}
print(opt)
print(names(demog)[lookatrows])
#
# should probably assess significance in terms of clusters of cog vars -- JOLO judgement line orientation
# 
lookatrowsscore<-rep(0,length(lookatrows))
havefrac<-0.96
IMGLISTGM<-Sys.glob("data/images/*nii.gz")
haveGM<-rep(FALSE,length(demog$pt_id))
GImageAddedAlready<-rep(FALSE,length(IMGLISTGM))
GIMAGELISTFORTHISSTUDY<-c("")
for ( i in 1:length(demog$pt_id) ){
  ID<-sub(",","",demog$pt_id[i])
  qct<-1
  for ( q in IMGLISTGM ) {
      bb<-grep(ID,q) # check if image has the right ID 
      filereadable<-file.access(q,mode=4) # check if image is there 
      if ( length(bb) == 1 & filereadable == 0  & GImageAddedAlready[qct] == 0  & haveGM[i] == 0 ) 
        {
                if ( sum(GImageAddedAlready) > 0 ){ 
                 GIMAGELISTFORTHISSTUDY<-paste(GIMAGELISTFORTHISSTUDY,q,sep='\n')
                }
                else {
                 GIMAGELISTFORTHISSTUDY<-paste(q,sep='\n')
                }
                GImageAddedAlready[qct]<-1
                haveGM[i]<-TRUE
                alreadyadded<-TRUE
         }
     qct<-qct+1 
      }
}
imglist<-strsplit(GIMAGELISTFORTHISSTUDY,'\n')[[1]]
print(lookatrowsscore)
WHICH<-which(  haveGM == TRUE ) 
nsub<-(length(WHICH))
 # now impute the variables we need & get the demographic descriptors 
unames<-names(demog)[grep("scale_adj",names(demog))]
mytests<-c("mmse","age","edu",unames,names(demog)[lookatrows] )
for ( mytest in mytests ) {
   var<-demog[,which(names(demog)==mytest)]
   var[ is.na(var) ]<-median( var , na.rm=T )
   demog[,which(names(demog)==mytest)]<-var
}

# demographics tables 
dxs       <-c("AD","bvFTD","nfaPPA","svPPA","CBS","NC")
dxnums<-c(1     ,    2      ,      3      ,      4    ,   5     ,   NA  )
demogtable<-data.frame( DX=dxs , N=rep(0,6),Age=rep("A",6), Education=rep("E",6),MMSE=rep("M",6) ,stringsAsFactors=FALSE)
ct<-1
options( digits = 3 )
myage<-demog$age[ WHICH ]
mymmse<-demog$mmse[ WHICH ]
myedu<-demog$edu[ WHICH ]
locdx  <- demog$dx.2[WHICH]
for ( mydx in  dxnums ) {
  slct<-( locdx == mydx )
  if ( is.na( mydx ) ) slct<-is.na( locdx )
  meanage<-round(mean(  myage[ slct ] , na.rm=T ) *100)/100
  sdage<-round(sd(  myage[ slct ] , na.rm=T )*100)/100
  demogtable$Age[ct]<-paste(meanage,sdage ,sep='/') 
  meanmmse<-round(mean(  mymmse[ slct ] , na.rm=T ) *100)/100
  sdmmse<-round(sd(  mymmse[ slct ] , na.rm=T )*100)/100
  demogtable$MMSE[ct]<-paste(meanmmse,sdmmse ,sep='/') 
  meanedu<-round(mean(  myedu[ slct ] , na.rm=T ) *100)/100
  sdedu<-round(sd(  myedu[ slct ] , na.rm=T )*100)/100
  demogtable$Education[ct]<-paste( meanedu,sdedu,sep='/') 
  demogtable$N[ct]<-sum( slct  , na.rm = T )
  ct<-ct+1
}
print( xtable( demogtable, caption="The demographics for this study of 164 subjects are listed as mean/standard deviation in each column.  For the testing and training split, subjects are matched on age, education and MMSE.  MMSE= Mini-Mental State Examination, AD= Alzheimer’s disease, bvFTD= behavioral variant of frontotemporal dementia, nfaPPA= non-fluent agrammatic variant of primary progressive aphasia; svPPA= semantic variant of primary progressive aphasia, CBS= corticobasal syndrome, NC= normal control." ) , file='./src/demog.txt')

# now we need to find out which tests are well represented ...
# below -- these rows have 100% hit rates 
fullrows<-c("")
for ( cols in lookatrows ){
  havecol<-sum(as.numeric(!is.na(demog[WHICH,cols])))
  havecol<-havecol/length(WHICH)
  tt<-sd(demog[WHICH,cols])
  if ( havecol == 1 & !is.na(tt) & tt > 0 ) {
    fullrows<-c(fullrows,cols)
  }
}
fullrows<-fullrows[2:length(fullrows)]
nc<-length(fullrows)
tt1p<-0 ; tt2p<-0 ; tt3p<-0 ; rval<-0.8
ct<-1
set.seed(11)
while ( tt1p < rval | tt2p < rval | tt3p < rval & ct < 550 ) {
  permutesubsin<-sample(1:nsub)
  w1<-round(length(permutesubsin)*0.52) # subset selection
  w2<-w1+1
  permutesubs<-permutesubsin[1:w1]# seq(1,nsub,by=2)
  permutesubs2<-permutesubsin[w2:nsub]# seq(2,nsub,by=2)
  tt1p<-t.test( demog[permutesubs,13] , demog[permutesubs2,13] )$p.value
  tt2p<-t.test( demog[permutesubs,14] , demog[permutesubs2,14] )$p.value
  tt3p<-t.test( demog[permutesubs,15] , demog[permutesubs2,15] )$p.value
  ct<-ct+1
}
library(pheatmap)
pdf(paste('figs/pbac_image_',nam,'.pdf',sep=''))
pheatmap( demog[WHICH,lookatrows] )
dev.off()
print(paste("Split:",length(permutesubs),length(permutesubs2),tt1p,tt2p,tt3p))
# define the matrix holding variables we want 
print(paste("nsub",nsub,"nc",nc,"opt",nam))
cogmat<-matrix(NA,nsub,nc-offset)
 ct<-1	
 nms<-rep(NA,nc)
 for ( x in (offset+1):nc ) {
  cogmat[,ct]<-as.numeric(demog[WHICH,as.numeric(fullrows[x])])
  nms[x]<-names(demog)[as.numeric(fullrows[x])]
  ct<-ct+1
 }
nw<-1:ncol(cogmat)
# cogmat<-decostand(cogmat,method='standardize',margin=2)
#
#######################################################################
#
 thmask<-paste(DIR,"gmask_2mmb.nii.gz",sep='')
maskimg<-antsImageRead(thmask,3)
mask<-maskimg == 1
trainmat<-matrix(NA,length(permutesubs),sum(mask))
ct<-1
for ( fn in imglist[permutesubs] ) {
  vec<-antsImageRead(fn,3)
  trainmat[ct,]<-subset( vec, mask )
  ct<-ct+1
}
testmat<-matrix(NA,length(permutesubs2),sum(mask))
ct<-1
for ( fn in imglist[permutesubs2] ) {
  vec<-antsImageRead(fn,3)
  testmat[ct,]<-subset( vec, mask )
  ct<-ct+1
}
@

<<cca2,include=TRUE, eval=FALSE,echo=TRUE>>=
trainmat<-residuals( lm( trainmat ~  age +  edu + mmse , data=demog[permutesubs,] ) )
testmat<-residuals( lm( testmat ~  age +  edu + mmse , data=demog[permutesubs2,] ) )
testmat<-(decostand( testmat , method='standardize',margin=2))
trainmat<-(decostand( trainmat , method='standardize',margin=2))

  if ( length( resUV ) != 5  & FALSE ) {
# do the univariate test to get the sparseness param 
  print("UNIVARIATE")
  voxside<-" ~ vox "
   if ( nam == "exec" ) myform<-as.formula( paste( unames[1], voxside ) )
   if ( nam == "lang" ) myform<-as.formula( paste( unames[2], voxside ) )
   if ( nam == "vs" ) myform<-as.formula( paste( unames[3], voxside ) )
   if ( nam == "mem" ) myform<-as.formula( paste( unames[5], voxside ) )
   if ( nam == "behav" ) myform<-as.formula( paste( unames[6], voxside ) )
   print( myform )
   bynum<-1
   ss<-seq(1,ncol(trainmat),by=bynum)
   ntests<-length( ss )
   progress <- txtProgressBar( min = 0, max = ntests,  style = 3 )
   upvs<-rep(1, ncol(trainmat) )
   for ( i in ss )
     {
     vox<-trainmat[,i]
     fit<-lm( myform,  data=demog[permutesubs,] )
     upvs[i]<-coefficients(summary(fit))[2,4]
     if( i %% 1000 == 0 )
       {
       setTxtProgressBar( progress, i )
       }
     }  
   sigthresh <- 0.01
   print("")
   sigfrac <- sum( upvs < 0.05 , na.rm=T ) / ntests * 5.0
   upvs[ is.na( upvs ) ]<-1
   qvsm <- upvs
   qvsm[ upvs < sigthresh ]<-1
   qvsm[ upvs >= sigthresh ]<-0
   qvsm <- qvsm / sum( qvsm )
   qvsm <-matrix( qvsm , nrow=1 )
   vox  <- testmat  %*% t( qvsm  )
   fit  <-lm( myform,  data=demog[permutesubs2,] )
   print( summary( fit ) )
   uvimg<-antsImageClone( maskimg )
   uvimg[ mask ]<- ( 1 - upvs  )
   antsImageWrite(  uvimg , paste(DIR,nam,"_uv.nii.gz",sep='') )
   resUV <- lappend( resUV , c( nam, coefficients(summary(fit))[2,4] ) )
   } # resUV length
# now do the multi-variate equivalent
 print(paste("MULTIVARIATE "))
 clustthresh<-10
 if ( length( sparMV ) < 5 ) {
 sparlist<-(c(1:20)/100) 
 corrlist<-list()
 for ( sigfrac in sparlist ) {
   print(paste("SEARCH:",sigfrac))
   ff<-sparseDecom2( inmatrix = list( trainmat,cogmat[permutesubs,nw] )  ,  inmask = c(maskimg, NA),    sparseness=c( sigfrac ,-1),nvecs=1,its=15,cthresh=c(clustthresh,0),perms=0,uselong=0,z=0,smooth=1 , robust = 1 )
   myproj1a<-trainmat %*% t( imageListToMatrix( ff$eig1 , maskimg ) )
   myproj1b<-cogmat[permutesubs,nw] %*% as.matrix( ff$eig2 )
   corrlist<-lappend( corrlist ,  cor.test( myproj1a, myproj1b)$est )
 }
 corrlist<-unlist( unlist(corrlist) )
 fit<-lm( corrlist ~ sparlist + I(sparlist^2) + I(sparlist^3) + I(sparlist^4) )
 pdf(paste('figs/sccan_param_',nam,'.pdf',sep=''))
 mytitle<-paste('Correlation v. Sparseness ',nam,sep='')
 visreg(fit,main=mytitle,xlab='Sparseness',ylab='SCCAN correlation',cex.main=2,cex.lab=2 )
 dev.off()
 sigfrac<-sparlist[  which( corrlist == max( corrlist )  ) ]
 sp<-data.frame( sparlist = (c(1:200)/1000) ) 
 pc<-predict( fit, newdata=sp )
 sigfrac<-sp$sparlist[  which.max( pc ) ]
 sparMV<-lappend( sparMV , sigfrac )
 }  else sigfrac<-sparMV[[ opt ]] 
 ff<-sparseDecom2( inmatrix = list( trainmat,cogmat[permutesubs,nw] )  ,  inmask = c(maskimg, NA),  sparseness=c( sigfrac ,-1),nvecs=1,its=15,cthresh=c(clustthresh,0),perms=0,uselong=0,z=0,smooth=1 )
 myproj1a<-trainmat %*% t( imageListToMatrix( ff$eig1 , maskimg ) )
 myproj1b<-cogmat[permutesubs,nw] %*% as.matrix( ff$eig2 ) 
 myproj2a<-testmat  %*% t( imageListToMatrix( ff$eig1 , maskimg ) )
 myproj2b<-cogmat[permutesubs2,nw] %*% as.matrix( ff$eig2 ) 
 print(as.matrix( ff$eig2 ) )
  imaging<-myproj2a[,1]
  cognition<-myproj2b[,1]
  myform<-as.formula( " cognition ~ imaging " )
  fit<-lm(  myform ,data=demog[permutesubs2,] )
  mypv<-coefficients(summary(fit))[2,4]
  print( summary( fit ) )		
@

<<cca3,include=TRUE, eval=FALSE,echo=FALSE>>=

  pdf(paste('figs/sccanpredict',nam,'.pdf',sep=''))
  mytitle<-paste('Testing: Thickness & ',nam,' spar=',round(sigfrac*100),'% p-value ',mypv,sep='')
  mytitle<-paste('Testing: Thickness & ',nam,' spar=',round(sigfrac*1000)/10,'%',sep='')
  mypvr<-round(mypv*10000)/10000
  visreg(fit,main=mytitle,xlab=paste('Thickness p-val',mypvr),ylab=nam,cex.main=2,cex.lab=2)
  dev.off()
  resMV<- lappend( resMV , c( nam, mypv ) )
  antsImageWrite(  ff$eig1[[1]] , paste(DIR,nam,".nii.gz",sep='') )

# finally, get the coordinates of this object 
 clust <- labelClusters(  ff$eig1[[1]] , minClusterSize=50, minThresh=1.e-5, maxThresh=1)
 if ( ! exists("mymni") ) {
    mymni<-list( antsImageRead(getANTsRData('mni'),3), 
                 antsImageRead(getANTsRData('mnib'),3), 
                 antsImageRead(getANTsRData('mnia'),3) )
  }
  gcoords<-getTemplateCoordinates( list(tem,clust) , mymni , convertToTal = TRUE, outprefix = "/tmp/Z" )
  print( xtable( gcoords$templatepoints, caption=paste('The approximate Talairach coordinates and AAL labels for network ',nam,' with significance',mypv,'.' ), label=paste("tab:",nam,sep='') ), file=paste('./src/',nam,'_network.txt',sep='') )
 print( paste(nam,sigfrac,'done') )

}


@ 


\bibliographystyle{IEEEtran}
\bibliography{src/cca}
\end{document}
